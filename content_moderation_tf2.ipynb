{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Content moderation in Tensorflow**\n",
        "\n",
        "*Problem statement:* A social media platform wants to automatically detect and remove offensive or harmful content from its platform. This includes content that is hate speech, bullying, or contains sexually explicit or violent language.\n",
        "\n",
        "*Suggested solution:* Use a deep learning-based text classification model such as a convolutional neural network (CNN) or a recurrent neural network (RNN) to automatically detect and remove offensive content.\n",
        "\n",
        "This solution can help the social media platform to automatically detect and remove offensive or harmful content from its platform, improving user experience, and the safety of the community.\n",
        "\n",
        "To productionize this code, you would need to consider several factors such as the infrastructure to run the model, the data pipeline, and monitor the model performance to make sure it's working as expected, and handle errors that might occur."
      ],
      "metadata": {
        "id": "0V4LHiUh4Erf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0C-1Rj14D4_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = pd.read_csv(\"social_media_posts.csv\")"
      ],
      "metadata": {
        "id": "gq7bxrmW5NIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the data\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # Removing punctuation\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "tBhfk9QX5Qf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"text\"] = data[\"text\"].apply(preprocess)"
      ],
      "metadata": {
        "id": "KzVKOc-K5Tvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the data\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(data[\"text\"])\n",
        "X = tokenizer.texts_to_sequences(data[\"text\"])\n",
        "X = keras.preprocessing.sequence.pad_sequences(X)"
      ],
      "metadata": {
        "id": "FYMT303k5Ws1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, data[\"label\"], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Lrktinw15Z4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(5000, 64, input_length=X.shape[1]))\n",
        "model.add(keras.layers.Conv1D(128, 3, activation='relu'))\n",
        "model.add(keras.layers.GlobalMaxPool1D())\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "vQ7gjuZy5cIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Yljn_Woh5ebR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "foRa5r6_5hcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.round(y_pred)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "2zSenrSE5j38"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}